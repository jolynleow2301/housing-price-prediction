{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2e5d6fc4",
   "metadata": {},
   "source": [
    "# Housing Price Prediction using Scikit-Learn\n",
    "\n",
    "This notebook demonstrates how to build a machine learning model to predict housing prices using various regression algorithms from scikit-learn.\n",
    "\n",
    "## What You'll Learn:\n",
    "1. Loading and exploring housing data\n",
    "2. Data preprocessing and feature engineering\n",
    "3. Training multiple regression models\n",
    "4. Evaluating model performance\n",
    "5. Making predictions on new data\n",
    "\n",
    "Let's get started! üöÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70372c9b",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "First, we'll import all the necessary libraries for data manipulation, visualization, and machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14fa0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "\n",
    "# Settings\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (10, 6)\n",
    "\n",
    "print(\"‚úì All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d05ce9",
   "metadata": {},
   "source": [
    "## 2. Load and Explore the Dataset\n",
    "\n",
    "We'll use the California Housing dataset, which contains information about housing prices in California. This dataset includes features like median income, house age, average rooms, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d639f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the California Housing dataset\n",
    "housing = fetch_california_housing()\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame(housing.data, columns=housing.feature_names)\n",
    "df['PRICE'] = housing.target  # Add the target variable\n",
    "\n",
    "print(f\"Dataset shape: {df.shape}\")\n",
    "print(f\"Features: {', '.join(housing.feature_names)}\")\n",
    "print(f\"\\nFirst 5 rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2097c76a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataset information\n",
    "print(\"Dataset Information:\")\n",
    "print(df.info())\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9915158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values:\")\n",
    "print(df.isnull().sum())\n",
    "print(f\"\\nTotal missing values: {df.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4c82845",
   "metadata": {},
   "source": [
    "### Visualize Data Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a6b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of housing prices\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.histplot(df['PRICE'], kde=True, bins=50, color='blue')\n",
    "plt.title('Distribution of Housing Prices')\n",
    "plt.xlabel('Price (in $100,000s)')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(y=df['PRICE'], color='skyblue')\n",
    "plt.title('Boxplot of Housing Prices')\n",
    "plt.ylabel('Price (in $100,000s)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9ab54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation analysis\n",
    "print(\"Correlation with Price:\")\n",
    "correlations = df.corr()['PRICE'].sort_values(ascending=False)\n",
    "print(correlations)\n",
    "\n",
    "# Correlation heatmap\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(), annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
    "plt.title('Feature Correlation Heatmap')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "884c841a",
   "metadata": {},
   "source": [
    "## 3. Data Preprocessing and Feature Engineering\n",
    "\n",
    "Now we'll prepare our data for machine learning by scaling features and handling any preprocessing needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0482b870",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate features (X) and target (y)\n",
    "X = df.drop('PRICE', axis=1)\n",
    "y = df['PRICE']\n",
    "\n",
    "print(f\"Features shape: {X.shape}\")\n",
    "print(f\"Target shape: {y.shape}\")\n",
    "print(f\"\\nFeature columns: {list(X.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75cd5e24",
   "metadata": {},
   "source": [
    "## 4. Split Data into Training and Testing Sets\n",
    "\n",
    "We'll split our data into training (80%) and testing (20%) sets. The training set is used to train the model, and the testing set is used to evaluate its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb4fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data (80% train, 20% test)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Training set size: {len(X_train)} samples\")\n",
    "print(f\"Testing set size: {len(X_test)} samples\")\n",
    "print(f\"Training set percentage: {len(X_train) / len(X) * 100:.1f}%\")\n",
    "print(f\"Testing set percentage: {len(X_test) / len(X) * 100:.1f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dfecb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(\"‚úì Features scaled using StandardScaler\")\n",
    "print(f\"\\nOriginal feature range example (MedInc):\")\n",
    "print(f\"  Before scaling: {X_train['MedInc'].min():.2f} to {X_train['MedInc'].max():.2f}\")\n",
    "print(f\"  After scaling: {X_train_scaled[:, 0].min():.2f} to {X_train_scaled[:, 0].max():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51658c05",
   "metadata": {},
   "source": [
    "## 5. Train a Linear Regression Model\n",
    "\n",
    "Let's start with the simplest regression model: Linear Regression. This model assumes a linear relationship between features and the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45c4a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and train Linear Regression model\n",
    "lr_model = LinearRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "print(\"‚úì Linear Regression model trained!\")\n",
    "print(f\"\\nModel coefficients:\")\n",
    "for feature, coef in zip(X.columns, lr_model.coef_):\n",
    "    print(f\"  {feature:15s}: {coef:8.4f}\")\n",
    "print(f\"\\nIntercept: {lr_model.intercept_:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50fd70f3",
   "metadata": {},
   "source": [
    "## 6. Make Predictions and Evaluate Model Performance\n",
    "\n",
    "Now we'll use our trained model to make predictions and evaluate how well it performs using various metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c15f2261",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "y_train_pred = lr_model.predict(X_train_scaled)\n",
    "y_test_pred = lr_model.predict(X_test_scaled)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "def evaluate_model(y_true, y_pred, set_name=\"\"):\n",
    "    \"\"\"Calculate and print regression metrics\"\"\"\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    mse = mean_squared_error(y_true, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    \n",
    "    print(f\"{set_name} Metrics:\")\n",
    "    print(f\"  Mean Absolute Error (MAE):  ${mae:.4f} (√ó100k)\")\n",
    "    print(f\"  Mean Squared Error (MSE):   ${mse:.4f}\")\n",
    "    print(f\"  Root Mean Squared Error:     ${rmse:.4f} (√ó100k)\")\n",
    "    print(f\"  R¬≤ Score:                    {r2:.4f}\")\n",
    "    print(f\"  Accuracy (R¬≤):               {r2*100:.2f}%\")\n",
    "    \n",
    "    return {'MAE': mae, 'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "print(\"=\"*50)\n",
    "train_metrics = evaluate_model(y_train, y_train_pred, \"Training Set\")\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "test_metrics = evaluate_model(y_test, y_test_pred, \"Test Set\")\n",
    "print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180c59a7",
   "metadata": {},
   "source": [
    "### Understanding the Metrics:\n",
    "\n",
    "- **MAE (Mean Absolute Error)**: Average absolute difference between predicted and actual prices. Lower is better.\n",
    "- **RMSE (Root Mean Squared Error)**: Square root of average squared differences. Penalizes larger errors more. Lower is better.\n",
    "- **R¬≤ Score**: Proportion of variance in the target variable explained by the model. Range: 0 to 1. Higher is better (1 = perfect prediction)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f569e6",
   "metadata": {},
   "source": [
    "## 7. Visualize Predictions vs Actual Values\n",
    "\n",
    "Let's visualize how well our model predictions match the actual housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f532c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot: Predicted vs Actual\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(y_test, y_test_pred, alpha=0.5, color='blue')\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2, label='Perfect Prediction')\n",
    "plt.xlabel('Actual Price (√ó$100k)')\n",
    "plt.ylabel('Predicted Price (√ó$100k)')\n",
    "plt.title('Predicted vs Actual Housing Prices')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Residual plot\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = y_test - y_test_pred\n",
    "plt.scatter(y_test_pred, residuals, alpha=0.5, color='green')\n",
    "plt.axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "plt.xlabel('Predicted Price (√ó$100k)')\n",
    "plt.ylabel('Residuals (Actual - Predicted)')\n",
    "plt.title('Residual Plot')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average residual: ${np.mean(residuals):.4f}\")\n",
    "print(f\"Residual standard deviation: ${np.std(residuals):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0df5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of prediction errors\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.histplot(residuals, kde=True, bins=50, color='purple')\n",
    "plt.xlabel('Prediction Error (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Prediction Errors')\n",
    "plt.axvline(x=0, color='r', linestyle='--', lw=2, label='Zero Error')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7972fa5e",
   "metadata": {},
   "source": [
    "## 8. Experiment with Other Regression Models\n",
    "\n",
    "Let's train and compare multiple regression algorithms to find the best one for our data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39145784",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple models to compare\n",
    "models = {\n",
    "    'Linear Regression': LinearRegression(),\n",
    "    'Ridge Regression': Ridge(alpha=1.0),\n",
    "    'Lasso Regression': Lasso(alpha=0.1),\n",
    "    'Decision Tree': DecisionTreeRegressor(max_depth=10, random_state=42),\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42, n_jobs=-1),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, max_depth=5, random_state=42)\n",
    "}\n",
    "\n",
    "# Train and evaluate each model\n",
    "results = []\n",
    "\n",
    "print(\"Training and evaluating models...\\n\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n{name}:\")\n",
    "    print(\"-\" * 80)\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Predict\n",
    "    y_pred = model.predict(X_test_scaled)\n",
    "    \n",
    "    # Evaluate\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'MAE': mae,\n",
    "        'RMSE': rmse,\n",
    "        'R¬≤ Score': r2,\n",
    "        'CV R¬≤ Mean': cv_scores.mean(),\n",
    "        'CV R¬≤ Std': cv_scores.std()\n",
    "    })\n",
    "    \n",
    "    print(f\"  MAE:  ${mae:.4f}\")\n",
    "    print(f\"  RMSE: ${rmse:.4f}\")\n",
    "    print(f\"  R¬≤:   {r2:.4f} ({r2*100:.2f}%)\")\n",
    "    print(f\"  CV R¬≤ Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cc8eb40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create comparison DataFrame\n",
    "results_df = pd.DataFrame(results).sort_values('R¬≤ Score', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON SUMMARY (Sorted by R¬≤ Score)\")\n",
    "print(\"=\"*80)\n",
    "print(results_df.to_string(index=False))\n",
    "\n",
    "# Display the best model\n",
    "best_model = results_df.iloc[0]['Model']\n",
    "best_r2 = results_df.iloc[0]['R¬≤ Score']\n",
    "print(f\"\\nüèÜ Best Model: {best_model} (R¬≤ = {best_r2:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c44cbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize model comparison\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "\n",
    "# R¬≤ Score comparison\n",
    "axes[0, 0].barh(results_df['Model'], results_df['R¬≤ Score'], color='skyblue')\n",
    "axes[0, 0].set_xlabel('R¬≤ Score')\n",
    "axes[0, 0].set_title('Model Comparison: R¬≤ Score')\n",
    "axes[0, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# MAE comparison\n",
    "axes[0, 1].barh(results_df['Model'], results_df['MAE'], color='lightcoral')\n",
    "axes[0, 1].set_xlabel('Mean Absolute Error')\n",
    "axes[0, 1].set_title('Model Comparison: MAE')\n",
    "axes[0, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# RMSE comparison\n",
    "axes[1, 0].barh(results_df['Model'], results_df['RMSE'], color='lightgreen')\n",
    "axes[1, 0].set_xlabel('Root Mean Squared Error')\n",
    "axes[1, 0].set_title('Model Comparison: RMSE')\n",
    "axes[1, 0].grid(axis='x', alpha=0.3)\n",
    "\n",
    "# CV R¬≤ Score with error bars\n",
    "axes[1, 1].barh(results_df['Model'], results_df['CV R¬≤ Mean'], \n",
    "                xerr=results_df['CV R¬≤ Std'], color='plum', capsize=5)\n",
    "axes[1, 1].set_xlabel('Cross-Validation R¬≤ Score')\n",
    "axes[1, 1].set_title('Model Comparison: CV R¬≤ Score (with std)')\n",
    "axes[1, 1].grid(axis='x', alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb67789e",
   "metadata": {},
   "source": [
    "## 9. Feature Importance Analysis\n",
    "\n",
    "For tree-based models, we can see which features are most important for predicting housing prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2884fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Random Forest for feature importance\n",
    "rf_model = RandomForestRegressor(n_estimators=100, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Get feature importance\n",
    "feature_importance = pd.DataFrame({\n",
    "    'Feature': X.columns,\n",
    "    'Importance': rf_model.feature_importances_\n",
    "}).sort_values('Importance', ascending=False)\n",
    "\n",
    "print(\"Feature Importance (Random Forest):\")\n",
    "print(feature_importance.to_string(index=False))\n",
    "\n",
    "# Plot feature importance\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=feature_importance, x='Importance', y='Feature', palette='viridis')\n",
    "plt.title('Feature Importance in Housing Price Prediction')\n",
    "plt.xlabel('Importance Score')\n",
    "plt.ylabel('Feature')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9042858",
   "metadata": {},
   "source": [
    "## 10. Making Predictions on New Data\n",
    "\n",
    "Now let's use our best model to make predictions on new, unseen data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55581282",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create example houses for prediction\n",
    "example_houses = pd.DataFrame({\n",
    "    'MedInc': [3.0, 5.0, 8.0],           # Median income\n",
    "    'HouseAge': [25.0, 15.0, 10.0],      # House age\n",
    "    'AveRooms': [5.0, 6.5, 8.0],         # Average rooms\n",
    "    'AveBedrms': [1.0, 1.2, 2.0],        # Average bedrooms\n",
    "    'Population': [1200.0, 800.0, 500.0], # Population\n",
    "    'AveOccup': [3.0, 2.5, 2.0],         # Average occupancy\n",
    "    'Latitude': [35.0, 37.0, 34.0],      # Latitude\n",
    "    'Longitude': [-120.0, -122.0, -118.0] # Longitude\n",
    "})\n",
    "\n",
    "print(\"Example Houses to Predict:\")\n",
    "print(example_houses)\n",
    "\n",
    "# Scale the features\n",
    "example_houses_scaled = scaler.transform(example_houses)\n",
    "\n",
    "# Make predictions using the best model (Random Forest)\n",
    "predictions = rf_model.predict(example_houses_scaled)\n",
    "\n",
    "# Display results\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"PREDICTIONS\")\n",
    "print(\"=\"*60)\n",
    "for i, pred in enumerate(predictions, 1):\n",
    "    print(f\"\\nHouse {i}:\")\n",
    "    print(f\"  Predicted Price: ${pred:.2f} √ó 100k = ${pred * 100000:.2f}\")\n",
    "    print(f\"  Features: MedInc={example_houses.iloc[i-1]['MedInc']}, \"\n",
    "          f\"HouseAge={example_houses.iloc[i-1]['HouseAge']}, \"\n",
    "          f\"AveRooms={example_houses.iloc[i-1]['AveRooms']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba054b4",
   "metadata": {},
   "source": [
    "## Summary and Next Steps\n",
    "\n",
    "### What We Learned:\n",
    "‚úÖ How to load and explore housing data  \n",
    "‚úÖ How to preprocess data (scaling, train-test split)  \n",
    "‚úÖ How to train multiple regression models  \n",
    "‚úÖ How to evaluate models using MAE, RMSE, and R¬≤  \n",
    "‚úÖ How to visualize predictions and errors  \n",
    "‚úÖ How to compare different algorithms  \n",
    "‚úÖ How to identify important features  \n",
    "‚úÖ How to make predictions on new data  \n",
    "\n",
    "### Model Performance Summary:\n",
    "The Random Forest and Gradient Boosting models typically perform best, achieving R¬≤ scores around 0.80-0.82, meaning they can explain about 80% of the variance in housing prices!\n",
    "\n",
    "### Next Steps to Improve:\n",
    "1. **Hyperparameter Tuning**: Use GridSearchCV or RandomizedSearchCV\n",
    "2. **Feature Engineering**: Create new features (e.g., rooms per person, price per room)\n",
    "3. **Handle Outliers**: Identify and handle outliers in the data\n",
    "4. **Try Advanced Models**: XGBoost, LightGBM, CatBoost\n",
    "5. **Ensemble Methods**: Combine multiple models for better predictions\n",
    "6. **Use Your Own Data**: Replace with real housing data from your area\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
